{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3TWkMGeStm5vi1e2Jai50"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Convolutional Neural Network (CNN)**\n",
        "**Image Classification with CIFAR-10 Dataset.**\n",
        "Task 1.\n"
      ],
      "metadata": {
        "id": "GVJMPbZHsgNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1. *Import necessary libraries and load the dataset.*"
      ],
      "metadata": {
        "id": "SYrJ7bTLs2Dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#libraries\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn import linear_model\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "#loading data from cifar-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "cRCE7aJWsxCk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CIFAR-10 consists of 60000 RGB color images of 32x32 pixels and 10 classes. There are 6000 images per class, 5000 of which belong to the training set and 1000 to the test set."
      ],
      "metadata": {
        "id": "kl1NGAAnw9tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWm8rcDrumJb",
        "outputId": "935cb581-e863-4900-9098-1059da5249d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3MTddbVvG_Z",
        "outputId": "64d9b01f-28be-4a64-ffdf-b31e50306e41"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvjeDaUV2atC",
        "outputId": "c80d8cef-3e69-4be5-84cd-a02f91db678d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqjXi4rD26Wk",
        "outputId": "40a21454-23a4-44c1-da65-6a058d0c6be2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "id": "zHHaaFnqvv5s"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(x, y, index):\n",
        "    plt.figure(figsize = (15,2))\n",
        "    plt.imshow(x[index])\n",
        "    plt.xlabel(labels[y[index]])"
      ],
      "metadata": {
        "id": "CwnIduOvwjq2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_image(x_train, y_train, 9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "A7SpZZzlxyB0",
        "outputId": "b48853e2-3b08-4ddf-c85c-7faca7d5d47a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-389b209a61f7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-9aa656ee6d63>\u001b[0m in \u001b[0;36mshow_image\u001b[0;34m(x, y, index)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-Mj1b4Zy8eh",
        "outputId": "05ab5b7b-cc91-4302-f456-e72d1274d7c6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 59,  62,  63],\n",
              "         [ 43,  46,  45],\n",
              "         [ 50,  48,  43],\n",
              "         ...,\n",
              "         [158, 132, 108],\n",
              "         [152, 125, 102],\n",
              "         [148, 124, 103]],\n",
              "\n",
              "        [[ 16,  20,  20],\n",
              "         [  0,   0,   0],\n",
              "         [ 18,   8,   0],\n",
              "         ...,\n",
              "         [123,  88,  55],\n",
              "         [119,  83,  50],\n",
              "         [122,  87,  57]],\n",
              "\n",
              "        [[ 25,  24,  21],\n",
              "         [ 16,   7,   0],\n",
              "         [ 49,  27,   8],\n",
              "         ...,\n",
              "         [118,  84,  50],\n",
              "         [120,  84,  50],\n",
              "         [109,  73,  42]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[208, 170,  96],\n",
              "         [201, 153,  34],\n",
              "         [198, 161,  26],\n",
              "         ...,\n",
              "         [160, 133,  70],\n",
              "         [ 56,  31,   7],\n",
              "         [ 53,  34,  20]],\n",
              "\n",
              "        [[180, 139,  96],\n",
              "         [173, 123,  42],\n",
              "         [186, 144,  30],\n",
              "         ...,\n",
              "         [184, 148,  94],\n",
              "         [ 97,  62,  34],\n",
              "         [ 83,  53,  34]],\n",
              "\n",
              "        [[177, 144, 116],\n",
              "         [168, 129,  94],\n",
              "         [179, 142,  87],\n",
              "         ...,\n",
              "         [216, 184, 140],\n",
              "         [151, 118,  84],\n",
              "         [123,  92,  72]]],\n",
              "\n",
              "\n",
              "       [[[154, 177, 187],\n",
              "         [126, 137, 136],\n",
              "         [105, 104,  95],\n",
              "         ...,\n",
              "         [ 91,  95,  71],\n",
              "         [ 87,  90,  71],\n",
              "         [ 79,  81,  70]],\n",
              "\n",
              "        [[140, 160, 169],\n",
              "         [145, 153, 154],\n",
              "         [125, 125, 118],\n",
              "         ...,\n",
              "         [ 96,  99,  78],\n",
              "         [ 77,  80,  62],\n",
              "         [ 71,  73,  61]],\n",
              "\n",
              "        [[140, 155, 164],\n",
              "         [139, 146, 149],\n",
              "         [115, 115, 112],\n",
              "         ...,\n",
              "         [ 79,  82,  64],\n",
              "         [ 68,  70,  55],\n",
              "         [ 67,  69,  55]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[175, 167, 166],\n",
              "         [156, 154, 160],\n",
              "         [154, 160, 170],\n",
              "         ...,\n",
              "         [ 42,  34,  36],\n",
              "         [ 61,  53,  57],\n",
              "         [ 93,  83,  91]],\n",
              "\n",
              "        [[165, 154, 128],\n",
              "         [156, 152, 130],\n",
              "         [159, 161, 142],\n",
              "         ...,\n",
              "         [103,  93,  96],\n",
              "         [123, 114, 120],\n",
              "         [131, 121, 131]],\n",
              "\n",
              "        [[163, 148, 120],\n",
              "         [158, 148, 122],\n",
              "         [163, 156, 133],\n",
              "         ...,\n",
              "         [143, 133, 139],\n",
              "         [143, 134, 142],\n",
              "         [143, 133, 144]]],\n",
              "\n",
              "\n",
              "       [[[255, 255, 255],\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253],\n",
              "         ...,\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[113, 120, 112],\n",
              "         [111, 118, 111],\n",
              "         [105, 112, 106],\n",
              "         ...,\n",
              "         [ 72,  81,  80],\n",
              "         [ 72,  80,  79],\n",
              "         [ 72,  80,  79]],\n",
              "\n",
              "        [[111, 118, 110],\n",
              "         [104, 111, 104],\n",
              "         [ 99, 106,  98],\n",
              "         ...,\n",
              "         [ 68,  75,  73],\n",
              "         [ 70,  76,  75],\n",
              "         [ 78,  84,  82]],\n",
              "\n",
              "        [[106, 113, 105],\n",
              "         [ 99, 106,  98],\n",
              "         [ 95, 102,  94],\n",
              "         ...,\n",
              "         [ 78,  85,  83],\n",
              "         [ 79,  85,  83],\n",
              "         [ 80,  86,  84]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[ 35, 178, 235],\n",
              "         [ 40, 176, 239],\n",
              "         [ 42, 176, 241],\n",
              "         ...,\n",
              "         [ 99, 177, 219],\n",
              "         [ 79, 147, 197],\n",
              "         [ 89, 148, 189]],\n",
              "\n",
              "        [[ 57, 182, 234],\n",
              "         [ 44, 184, 250],\n",
              "         [ 50, 183, 240],\n",
              "         ...,\n",
              "         [156, 182, 200],\n",
              "         [141, 177, 206],\n",
              "         [116, 149, 175]],\n",
              "\n",
              "        [[ 98, 197, 237],\n",
              "         [ 64, 189, 252],\n",
              "         [ 69, 192, 245],\n",
              "         ...,\n",
              "         [188, 195, 206],\n",
              "         [119, 135, 147],\n",
              "         [ 61,  79,  90]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 73,  79,  77],\n",
              "         [ 53,  63,  68],\n",
              "         [ 54,  68,  80],\n",
              "         ...,\n",
              "         [ 17,  40,  64],\n",
              "         [ 21,  36,  51],\n",
              "         [ 33,  48,  49]],\n",
              "\n",
              "        [[ 61,  68,  75],\n",
              "         [ 55,  70,  86],\n",
              "         [ 57,  79, 103],\n",
              "         ...,\n",
              "         [ 24,  48,  72],\n",
              "         [ 17,  35,  53],\n",
              "         [  7,  23,  32]],\n",
              "\n",
              "        [[ 44,  56,  73],\n",
              "         [ 46,  66,  88],\n",
              "         [ 49,  77, 105],\n",
              "         ...,\n",
              "         [ 27,  52,  77],\n",
              "         [ 21,  43,  66],\n",
              "         [ 12,  31,  50]]],\n",
              "\n",
              "\n",
              "       [[[189, 211, 240],\n",
              "         [186, 208, 236],\n",
              "         [185, 207, 235],\n",
              "         ...,\n",
              "         [175, 195, 224],\n",
              "         [172, 194, 222],\n",
              "         [169, 194, 220]],\n",
              "\n",
              "        [[194, 210, 239],\n",
              "         [191, 207, 236],\n",
              "         [190, 206, 235],\n",
              "         ...,\n",
              "         [173, 192, 220],\n",
              "         [171, 191, 218],\n",
              "         [167, 190, 216]],\n",
              "\n",
              "        [[208, 219, 244],\n",
              "         [205, 216, 240],\n",
              "         [204, 215, 239],\n",
              "         ...,\n",
              "         [175, 191, 217],\n",
              "         [172, 190, 216],\n",
              "         [169, 191, 215]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[207, 199, 181],\n",
              "         [203, 195, 175],\n",
              "         [203, 196, 173],\n",
              "         ...,\n",
              "         [135, 132, 127],\n",
              "         [162, 158, 150],\n",
              "         [168, 163, 151]],\n",
              "\n",
              "        [[198, 190, 170],\n",
              "         [189, 181, 159],\n",
              "         [180, 172, 147],\n",
              "         ...,\n",
              "         [178, 171, 160],\n",
              "         [175, 169, 156],\n",
              "         [175, 169, 154]],\n",
              "\n",
              "        [[198, 189, 173],\n",
              "         [189, 181, 162],\n",
              "         [178, 170, 149],\n",
              "         ...,\n",
              "         [195, 184, 169],\n",
              "         [196, 189, 171],\n",
              "         [195, 190, 171]]],\n",
              "\n",
              "\n",
              "       [[[229, 229, 239],\n",
              "         [236, 237, 247],\n",
              "         [234, 236, 247],\n",
              "         ...,\n",
              "         [217, 219, 233],\n",
              "         [221, 223, 234],\n",
              "         [222, 223, 233]],\n",
              "\n",
              "        [[222, 221, 229],\n",
              "         [239, 239, 249],\n",
              "         [233, 234, 246],\n",
              "         ...,\n",
              "         [223, 223, 236],\n",
              "         [227, 228, 238],\n",
              "         [210, 211, 220]],\n",
              "\n",
              "        [[213, 206, 211],\n",
              "         [234, 232, 239],\n",
              "         [231, 233, 244],\n",
              "         ...,\n",
              "         [220, 220, 232],\n",
              "         [220, 219, 232],\n",
              "         [202, 203, 215]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[150, 143, 135],\n",
              "         [140, 135, 127],\n",
              "         [132, 127, 120],\n",
              "         ...,\n",
              "         [224, 222, 218],\n",
              "         [230, 228, 225],\n",
              "         [241, 241, 238]],\n",
              "\n",
              "        [[137, 132, 126],\n",
              "         [130, 127, 120],\n",
              "         [125, 121, 115],\n",
              "         ...,\n",
              "         [181, 180, 178],\n",
              "         [202, 201, 198],\n",
              "         [212, 211, 207]],\n",
              "\n",
              "        [[122, 119, 114],\n",
              "         [118, 116, 110],\n",
              "         [120, 116, 111],\n",
              "         ...,\n",
              "         [179, 177, 173],\n",
              "         [164, 164, 162],\n",
              "         [163, 163, 161]]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3. *Preprocessing*"
      ],
      "metadata": {
        "id": "D4BLKgsgy1yU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=x_train/255\n",
        "y_test = y_test/255"
      ],
      "metadata": {
        "id": "Hz9oroTJzOli"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#one-hot_encoding\n",
        "y_train_one_hot = to_categorical(y_train, num_classes = 10)\n",
        "y_test_one_hot = to_categorical(y_test, num_classes = 10)"
      ],
      "metadata": {
        "id": "9yeu4vLP07_X"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data augmentation"
      ],
      "metadata": {
        "id": "V0OXRZQe55mZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")"
      ],
      "metadata": {
        "id": "IwKWW7I95xRT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model**.\n",
        "Applied Sequential model, which is a convenient and simple way to build neural networks. It is widely used for image classification tasks, here a linear stack of layers is sufficient."
      ],
      "metadata": {
        "id": "RjklxyMkwXuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Flatten(input_shape=(32, 32, 3)),  #reshapes the input data from (32, 32, 3) to a flat vector of size 32 x 32 x 3 = 3072 before feeding it to the first layer.\n",
        "    Dense(128, activation='relu'), #first dense layer with 128 neurons using ReLU activation function\n",
        "    BatchNormalization(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax') #softmax activation function for multi-class classification problems\n",
        "]) #a simple neural network using the Keras Sequential API"
      ],
      "metadata": {
        "id": "aQg8H68rw0SB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy']) #configuring the model for training\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit(datagen.flow(x_train, y_train_one_hot, batch_size=32), epochs=50, validation_data=(x_test, y_test_one_hot), callbacks=[early_stopping]) #train with data augm."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROP3F_9OzApy",
        "outputId": "d9a08623-96b6-47e0-9fcf-e67c7d30b29f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 51s 29ms/step - loss: 1.9057 - accuracy: 0.3152 - val_loss: 63.3113 - val_accuracy: 0.7686\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 48s 30ms/step - loss: 1.8150 - accuracy: 0.3478 - val_loss: 158.3584 - val_accuracy: 0.4879\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 46s 29ms/step - loss: 1.7587 - accuracy: 0.3672 - val_loss: 63.7592 - val_accuracy: 0.7073\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 46s 30ms/step - loss: 1.7332 - accuracy: 0.3786 - val_loss: 821.9136 - val_accuracy: 0.0069\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e97149fe2f0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5d5omMc248Z",
        "outputId": "5d344324-3e0f-4b85-c010-7ffe97313967"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 3072)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               393344    \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 128)               512       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 402762 (1.54 MB)\n",
            "Trainable params: 402506 (1.54 MB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(x_test, y_test_one_hot)\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD3_vHiv5VUi",
        "outputId": "ccae0ec6-1e80-471f-facf-5cbf382ba10f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 63.3113 - accuracy: 0.7686\n",
            "Test Loss: 63.31129837036133\n",
            "Test Accuracy: 0.7685999870300293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GLgKWBP5mZA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EfficientNet Model.**\n"
      ],
      "metadata": {
        "id": "r1VcmGxLhARm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit(datagen.flow(x_train, y_train_one_hot, batch_size=32), epochs=50, validation_data=(x_test, y_test_one_hot), callbacks=[early_stopping])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "mN1qcrw9F_rq",
        "outputId": "7c4714bb-ddc6-40a0-e001-62197b421726"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16705208/16705208 [==============================] - 2s 0us/step\n",
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 148s 89ms/step - loss: 2.3044 - accuracy: 0.1001 - val_loss: 2.3085 - val_accuracy: 0.0855\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 137s 88ms/step - loss: 2.3028 - accuracy: 0.0978 - val_loss: 2.3227 - val_accuracy: 0.0405\n",
            "Epoch 3/50\n",
            " 775/1563 [=============>................] - ETA: 1:03 - loss: 2.3028 - accuracy: 0.0970"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-fb04691d45f0>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                         ):\n\u001b[1;32m   1741\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    855\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m       (concrete_function,\n\u001b[1;32m    147\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    149\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1348\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}